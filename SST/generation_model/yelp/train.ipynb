{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP8T+Y9H2B96Jshn5TMUd2H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2pterons/twigfarm/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlOQ0LRKLCwp"
      },
      "source": [
        "import pdb\n",
        "#pdb.set_trace()\n",
        "\n",
        "import torch\n",
        "'''\n",
        "print(torch.cuda.get_device_name(0)\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.__version__)\n",
        "# pip install torch===1.2.0 torchvision===0.4.0 -f 업그레이드 완료\n",
        "torch.rand(5)\n",
        "'''\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import random\n",
        "\n",
        "import transformers\n",
        "'''\n",
        "from transformers import (set_seed,\n",
        "                          TrainingArguments,\n",
        "                          Trainer,\n",
        "                          GPT2Config,\n",
        "                          GPT2Tokenizer,\n",
        "                          AdamW, \n",
        "                          get_linear_schedule_with_warmup,\n",
        "                          GPT2ForSequenceClassification)\n",
        "'''\n",
        "\n",
        "#import gpt2\n",
        "from transformers import *\n",
        "gpt_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "\n",
        "path = os.getcwd()\n",
        "print(path)\n",
        "\n",
        "## 초기화\n",
        "from gen_model import *\n",
        "genmodel = styletransfer().cuda()\n",
        "genmodel.train()\n",
        "\n",
        "\n",
        "sys.path.insert(0, \"/home/tf-dev-01/workspace_sol/style-transfer/Stable-Style-Transformer/generation_model/yelp/classifier\")\n",
        "\n",
        "from dis_model import *\n",
        "dismodel = findattribute().cuda()\n",
        "dismodel_name='cls_model_3'\n",
        "dismodel.load_state_dict(torch.load('/home/tf-dev-01/workspace_sol/style-transfer/Stable-Style-Transformer/generation_model/yelp/classifier/models/{}'.format(dismodel_name)))\n",
        "dismodel.eval()\n",
        "\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "from tensorboardX import SummaryWriter\n",
        "summary = SummaryWriter(logdir='./logs')\n",
        "\n",
        "def main():\n",
        "    \n",
        "    f = open('gpt_yelp_vocab.json')\n",
        "\n",
        "    token2num = json.load(f)\n",
        "\n",
        "    num2token = {}\n",
        "    for key, value in token2num.items():\n",
        "        num2token[value] = key\n",
        "    f.close()\n",
        "    data_path = \"/home/tf-dev-01/workspace_sol/style-transfer/Sentiment-and-Style-Transfer/data\"\n",
        "#    data_path = \"/DATA/joosung/sentiment_data/Sentiment-and-Style-Transfer-master/data\"\n",
        "    train_yelp_neg_path = data_path + \"/yelp/sentiment.train.0\"\n",
        "    train_yelp_neg_open = open(train_yelp_neg_path, \"r\")\n",
        "    train_yelp_neg_dataset = train_yelp_neg_open.readlines()\n",
        "    yelp_neg_dataset = train_yelp_neg_dataset\n",
        "    \n",
        "    neg_len = len(yelp_neg_dataset)\n",
        "    train_yelp_neg_open.close()\n",
        "\n",
        "    train_yelp_pos_path = data_path + \"/yelp/sentiment.train.1\"\n",
        "    train_yelp_pos_open = open(train_yelp_pos_path, \"r\")\n",
        "    train_yelp_pos_dataset = train_yelp_pos_open.readlines()\n",
        "    yelp_pos_dataset = train_yelp_pos_dataset\n",
        "    \n",
        "    pos_len = len(yelp_pos_dataset)\n",
        "    train_yelp_pos_open.close()\n",
        "\n",
        "    \"\"\"training parameter\"\"\"\n",
        "    aed_initial_lr = 0.00001\n",
        "    gen_initial_lr = 0.001\n",
        "    aed_trainer = optim.Adamax(genmodel.aed_params, lr=aed_initial_lr) # initial 0.0005\n",
        "    gen_trainer = optim.Adamax(genmodel.aed_params, lr=gen_initial_lr) # initial 0.0001\n",
        "    max_grad_norm = 20\n",
        "    batch = 1\n",
        "    epoch = 6\n",
        "    stop_point = pos_len*epoch\n",
        "    \n",
        "    pre_epoch = 0\n",
        "    for start in tqdm(range(0, stop_point)):\n",
        "        ## learing rate decay\n",
        "        now_epoch = (start+1)//pos_len\n",
        "            \n",
        "        \"\"\"data start point\"\"\"\n",
        "        neg_start = start%neg_len\n",
        "        pos_start = start%pos_len\n",
        "\n",
        "        \"\"\"data setting\"\"\"\n",
        "        neg_sentence = yelp_neg_dataset[neg_start].strip()\n",
        "        pos_sentence = yelp_pos_dataset[pos_start].strip()                \n",
        "\n",
        "        neg_labels = [] # negative labels\n",
        "        neg_labels.append([1,0])\n",
        "        neg_attribute = torch.from_numpy(np.asarray(neg_labels)).type(torch.FloatTensor).cuda()\n",
        "\n",
        "        pos_labels = [] # positive labels\n",
        "        pos_labels.append([0,1])\n",
        "        pos_attribute = torch.from_numpy(np.asarray(pos_labels)).type(torch.FloatTensor).cuda()\n",
        "\n",
        "        sentences = [neg_sentence, pos_sentence]\n",
        "        attributes = [neg_attribute, pos_attribute]\n",
        "        sentiments = [0, 1]\n",
        "\n",
        "        \"\"\"data input\"\"\"\n",
        "        for i in range(2):\n",
        "            # k=0: negative, k=1: positive\n",
        "            sentence = sentences[i]\n",
        "            attribute = attributes[i] # for decoder\n",
        "            fake_attribute = attributes[abs(1-i)] # for generate\n",
        "#             sentiment = sentiments[i] # for delete\n",
        "\n",
        "            token_idx = torch.tensor(gpt_tokenizer.encode(sentence)).unsqueeze(0).cuda()\n",
        "\n",
        "            # delete model\n",
        "            max_len = int(token_idx.shape[1]/2)\n",
        "            dis_out = dismodel.discriminator(token_idx)    \n",
        "            sentiment = dis_out.argmax(1).cpu().item() ## 변경점 for delete\n",
        "            \n",
        "            del_idx = token_idx\n",
        "            for k in range(max_len):\n",
        "                del_idx = dismodel.att_prob(del_idx, sentiment)                \n",
        "                dis_out = dismodel.discriminator(del_idx)    \n",
        "                sent_porb = F.softmax(dis_out, 1).squeeze(0)[sentiment].cpu().detach().numpy().item()\n",
        "                if sent_porb < 0.7:\n",
        "                    break       \n",
        "                    \n",
        "            \"\"\"auto-encoder loss & traning\"\"\"\n",
        "            # training using discriminator loss\n",
        "            enc_out = genmodel.encoder(del_idx)\n",
        "            dec_out, vocab_out = genmodel.decoder(enc_out, token_idx, attribute)\n",
        "\n",
        "            ## calculation loss\n",
        "            recon_loss = genmodel.recon_loss(token_idx, vocab_out)\n",
        "            summary.add_scalar('reconstruction loss', recon_loss.item(), start)\n",
        "            \n",
        "            aed_trainer.zero_grad()\n",
        "            recon_loss.backward(retain_graph=True) # retain_graph=True\n",
        "            grad_norm = torch.nn.utils.clip_grad_norm_(genmodel.aed_params, max_grad_norm)            \n",
        "            aed_trainer.step()\n",
        "            \n",
        "            \"\"\"decoder classification loss & training\"\"\"\n",
        "            ## calculation loss\n",
        "            gen_cls_out = dismodel.gen_discriminator(vocab_out)\n",
        "\n",
        "            ## calculation loss\n",
        "            gen_cls_loss = genmodel.cls_loss(attribute, gen_cls_out)\n",
        "            summary.add_scalar('generated sentence loss', gen_cls_loss.item(), start)\n",
        "\n",
        "            gen_trainer.zero_grad()\n",
        "            gen_cls_loss.backward() # retain_graph=True\n",
        "            grad_norm = torch.nn.utils.clip_grad_norm_(genmodel.aed_params, max_grad_norm)\n",
        "            gen_trainer.step()\n",
        "            \n",
        "        \n",
        "        \"\"\"savining point\"\"\"\n",
        "        if (start+1)%pos_len == 0:\n",
        "            random.shuffle(yelp_neg_dataset)\n",
        "            random.shuffle(yelp_pos_dataset)\n",
        "            save_model((start+1)//pos_len)        \n",
        "    save_model('final') # final_model    \n",
        "\n",
        "    \n",
        "def save_model(iter):\n",
        "    if not os.path.exists('models/'):\n",
        "        os.makedirs('models/')\n",
        "    torch.save(genmodel.state_dict(), 'models/gen_model_{}'.format(iter))  \n",
        "    \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    torch.cuda.empty_cache()\n",
        "    main()\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}